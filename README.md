# galaxy_classifier

The Galaxy Zoo is a project motivated to provide information about galaxy features to astronomers in order to more easily acquire data required for their research. Observers at home follow a series of questions about an image in order to identify various morphological features of galaxies. Galaxy morphology can tell us much more than just the shape of a certain galaxy. Spiral galaxies tell us that the galaxy is still young, and that its arms are active regions of star formation. Even more useful than the class of a galaxy are the specific features within it. If an astronomer wanted to study ongoing mergers within galaxies, then they could search Galaxy Zoo for images with multiple nuclei and strong tidal features. If one wanted to study or find new black holes, they could also search for nuclear bulges within the images. The same goes for bars and star birth. Labeling galaxy features creates a gateway to many more specific problems and studies. The problem with Galaxy Zoo is that it requires many man hours to get these results. Not only does each observer have to answer a series of questions for each image, but they need many observers to do a single image in order to get good probabilities. The hope for this project is to be accurately recreate the human probabilities given the images. This will prove that the model will be able to perform just as well as several humans on these images, thus decreasing the amount of man hours required to label these images and giving astronomers better turnaround time for acquiring data.

The original goal of this project were to participate in this Kaggle competition https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/overview/the-galaxy-zoo-decision-tree. This would involve training on ~61,000 images and testing on ~80,000 images. I plan to use a CNN in order to accompish this. The model would take in an image of a galaxy, and train given the probabilities for each feature for that image. I would then test the output of the model to predict these probabilities given these images. The preprocessing of the data would include creating a data loader in order to train in batches, croping, resizing, random horizontal flips, and random rotations in order to make the model rotation invariant. 

The project will ultimately have to descope to training on less images, and using a validation loss rather than a Kaggle loss. The training and testing would take multiple days, even with a GPU. For sake of time and resources, I have decided to descope to training on 8000 images and validating on 2000 images.
